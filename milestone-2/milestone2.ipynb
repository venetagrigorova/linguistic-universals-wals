{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699e81d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\.conda\\envs\\linguistic-universals-wals-env\\lib\\site-packages\\lang2vec\\lang2vec.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import lang2vec.lang2vec as l2v\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb3b501",
   "metadata": {},
   "source": [
    "### 1. Fetch WALS syntax features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a3282ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4005, 103)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_SVO</th>\n",
       "      <th>S_SOV</th>\n",
       "      <th>S_VSO</th>\n",
       "      <th>S_VOS</th>\n",
       "      <th>S_OVS</th>\n",
       "      <th>S_OSV</th>\n",
       "      <th>S_SUBJECT_BEFORE_VERB</th>\n",
       "      <th>S_SUBJECT_AFTER_VERB</th>\n",
       "      <th>S_OBJECT_AFTER_VERB</th>\n",
       "      <th>S_OBJECT_BEFORE_VERB</th>\n",
       "      <th>...</th>\n",
       "      <th>S_XVO</th>\n",
       "      <th>S_XOV</th>\n",
       "      <th>S_OXV</th>\n",
       "      <th>S_OVX</th>\n",
       "      <th>S_OBLIQUE_AFTER_VERB</th>\n",
       "      <th>S_OBLIQUE_AFTER_OBJECT</th>\n",
       "      <th>S_OBLIQUE_BEFORE_VERB</th>\n",
       "      <th>S_OBLIQUE_BEFORE_OBJECT</th>\n",
       "      <th>S_ARTICLE_WORD_BEFORE_NOUN</th>\n",
       "      <th>S_ARTICLE_WORD_AFTER_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hye</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omb</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dit</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     S_SVO  S_SOV  S_VSO  S_VOS  S_OVS  S_OSV  S_SUBJECT_BEFORE_VERB  \\\n",
       "hye    1.0    1.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "moq    NaN    NaN    NaN    NaN    NaN    NaN                    NaN   \n",
       "omb    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
       "dit    NaN    NaN    NaN    NaN    NaN    NaN                    NaN   \n",
       "crc    NaN    NaN    NaN    NaN    NaN    NaN                    NaN   \n",
       "\n",
       "     S_SUBJECT_AFTER_VERB  S_OBJECT_AFTER_VERB  S_OBJECT_BEFORE_VERB  ...  \\\n",
       "hye                   0.0                  1.0                   1.0  ...   \n",
       "moq                   NaN                  NaN                   NaN  ...   \n",
       "omb                   0.0                  1.0                   0.0  ...   \n",
       "dit                   NaN                  NaN                   NaN  ...   \n",
       "crc                   NaN                  NaN                   NaN  ...   \n",
       "\n",
       "     S_XVO  S_XOV  S_OXV  S_OVX  S_OBLIQUE_AFTER_VERB  S_OBLIQUE_AFTER_OBJECT  \\\n",
       "hye    NaN    NaN    NaN    NaN                   NaN                     NaN   \n",
       "moq    NaN    NaN    NaN    NaN                   NaN                     NaN   \n",
       "omb    0.0    0.0    0.0    0.0                   1.0                     1.0   \n",
       "dit    NaN    NaN    NaN    NaN                   NaN                     NaN   \n",
       "crc    NaN    NaN    NaN    NaN                   NaN                     NaN   \n",
       "\n",
       "     S_OBLIQUE_BEFORE_VERB  S_OBLIQUE_BEFORE_OBJECT  \\\n",
       "hye                    NaN                      NaN   \n",
       "moq                    NaN                      NaN   \n",
       "omb                    0.0                      0.0   \n",
       "dit                    NaN                      NaN   \n",
       "crc                    NaN                      NaN   \n",
       "\n",
       "     S_ARTICLE_WORD_BEFORE_NOUN  S_ARTICLE_WORD_AFTER_NOUN  \n",
       "hye                         NaN                        NaN  \n",
       "moq                         NaN                        NaN  \n",
       "omb                         NaN                        NaN  \n",
       "dit                         NaN                        NaN  \n",
       "crc                         NaN                        NaN  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "languages = [\n",
    "    \"eng\",\n",
    "    \"deu\",\n",
    "    \"spa\",\n",
    "    \"rus\",\n",
    "    \"jpn\",\n",
    "    \"hin\",\n",
    "    \"tur\",\n",
    "    \"ara\",\n",
    "    \"por\",\n",
    "    \"ita\",\n",
    "  ]\n",
    "languages = list(l2v.available_languages())\n",
    "\n",
    "# iso_code -> feature_vector\n",
    "features_dict = l2v.get_features(languages, \"syntax_wals\", header=True)\n",
    "\n",
    "# extract feature names\n",
    "feature_names = features_dict[\"CODE\"]\n",
    "\n",
    "# build a matrix for all languages\n",
    "# missing values are encoded as the string '--'\n",
    "rows = []\n",
    "valid_langs = []\n",
    "\n",
    "for lang in languages:\n",
    "    if lang not in features_dict:\n",
    "        print(f\"[warning] language {lang} not available, skipping.\")\n",
    "        continue\n",
    "\n",
    "    rows.append(features_dict[lang])\n",
    "    valid_langs.append(lang)\n",
    "\n",
    "# each row is a language, each column is a wals feature\n",
    "all_syntax_features_df = pd.DataFrame(rows, index=valid_langs, columns=feature_names)\n",
    "\n",
    "# replace the missing marker '--' with np.nan so pandas can handle it\n",
    "all_syntax_features_df = all_syntax_features_df.replace(\"--\", np.nan)\n",
    "\n",
    "print(\"shape:\", all_syntax_features_df.shape)\n",
    "display(all_syntax_features_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e21c6",
   "metadata": {},
   "source": [
    "Selecting only the features related to 49A, 50A, 81A, 85A-90A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (focused on 49A, 50A, 81A, 85A–90A): (4005, 28)\n",
      "first few columns: [np.str_('S_CASE_PREFIX'), np.str_('S_CASE_SUFFIX'), np.str_('S_CASE_PROCLITIC'), np.str_('S_CASE_ENCLITIC'), np.str_('S_CASE_MARK'), np.str_('S_SVO'), np.str_('S_SOV'), np.str_('S_VSO'), np.str_('S_VOS'), np.str_('S_OVS')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_CASE_PREFIX</th>\n",
       "      <th>S_CASE_SUFFIX</th>\n",
       "      <th>S_CASE_PROCLITIC</th>\n",
       "      <th>S_CASE_ENCLITIC</th>\n",
       "      <th>S_CASE_MARK</th>\n",
       "      <th>S_SVO</th>\n",
       "      <th>S_SOV</th>\n",
       "      <th>S_VSO</th>\n",
       "      <th>S_VOS</th>\n",
       "      <th>S_OVS</th>\n",
       "      <th>...</th>\n",
       "      <th>S_ANY_AGREEMENT_ON_ADJECTIVES</th>\n",
       "      <th>S_DEMONSTRATIVE_WORD_BEFORE_NOUN</th>\n",
       "      <th>S_DEMONSTRATIVE_WORD_AFTER_NOUN</th>\n",
       "      <th>S_DEMONSTRATIVE_PREFIX</th>\n",
       "      <th>S_DEMONSTRATIVE_SUFFIX</th>\n",
       "      <th>S_NUMERAL_BEFORE_NOUN</th>\n",
       "      <th>S_NUMERAL_AFTER_NOUN</th>\n",
       "      <th>S_RELATIVE_BEFORE_NOUN</th>\n",
       "      <th>S_RELATIVE_AFTER_NOUN</th>\n",
       "      <th>S_RELATIVE_AROUND_NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hye</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omb</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dit</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     S_CASE_PREFIX  S_CASE_SUFFIX  S_CASE_PROCLITIC  S_CASE_ENCLITIC  \\\n",
       "hye            0.0            1.0               0.0              0.0   \n",
       "moq            NaN            NaN               NaN              NaN   \n",
       "omb            0.0            0.0               0.0              0.0   \n",
       "dit            NaN            NaN               NaN              NaN   \n",
       "crc            NaN            NaN               NaN              NaN   \n",
       "\n",
       "     S_CASE_MARK  S_SVO  S_SOV  S_VSO  S_VOS  S_OVS  ...  \\\n",
       "hye          1.0    1.0    1.0    0.0    0.0    0.0  ...   \n",
       "moq          NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
       "omb          0.0    1.0    0.0    0.0    0.0    0.0  ...   \n",
       "dit          NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
       "crc          NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
       "\n",
       "     S_ANY_AGREEMENT_ON_ADJECTIVES  S_DEMONSTRATIVE_WORD_BEFORE_NOUN  \\\n",
       "hye                            NaN                               1.0   \n",
       "moq                            NaN                               NaN   \n",
       "omb                            NaN                               0.0   \n",
       "dit                            NaN                               NaN   \n",
       "crc                            NaN                               NaN   \n",
       "\n",
       "     S_DEMONSTRATIVE_WORD_AFTER_NOUN  S_DEMONSTRATIVE_PREFIX  \\\n",
       "hye                              0.0                     0.0   \n",
       "moq                              NaN                     NaN   \n",
       "omb                              1.0                     0.0   \n",
       "dit                              NaN                     NaN   \n",
       "crc                              NaN                     NaN   \n",
       "\n",
       "     S_DEMONSTRATIVE_SUFFIX  S_NUMERAL_BEFORE_NOUN  S_NUMERAL_AFTER_NOUN  \\\n",
       "hye                     0.0                    1.0                   0.0   \n",
       "moq                     NaN                    NaN                   NaN   \n",
       "omb                     0.0                    0.0                   1.0   \n",
       "dit                     NaN                    NaN                   NaN   \n",
       "crc                     NaN                    NaN                   NaN   \n",
       "\n",
       "     S_RELATIVE_BEFORE_NOUN  S_RELATIVE_AFTER_NOUN  S_RELATIVE_AROUND_NOUN  \n",
       "hye                     1.0                    1.0                     0.0  \n",
       "moq                     NaN                    NaN                     NaN  \n",
       "omb                     0.0                    1.0                     0.0  \n",
       "dit                     NaN                    NaN                     NaN  \n",
       "crc                     NaN                    NaN                     NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# keep columns whose name contains any of the given substrings\n",
    "def select_cols(df, keywords):\n",
    "    return [c for c in df.columns if any(k in c for k in keywords)]\n",
    "\n",
    "cols_49A = select_cols(all_syntax_features_df, [\"CASE\", \"CASES\"]) # 49A number of cases\n",
    "cols_50A = select_cols(all_syntax_features_df, [\"ASYMMETRIC\"]) # 50A asymmetrical case marking\n",
    "cols_81A = select_cols(all_syntax_features_df, [\"SVO\", \"SOV\", \"VSO\", \"VOS\", \"OVS\", \"OSV\"]) # 81A basic order\n",
    "cols_85A = select_cols(all_syntax_features_df, [\"ADPOSITION\", \"ADP\",\"S_ADPOSITION_BEFORE_NOUN\", \"S_ADPOSITION_AFTER_NOUN\"]) # 85A adposition + np\n",
    "cols_86A = select_cols(all_syntax_features_df, [\"S_POSSESSOR_BEFORE_NOUN\", \"S_POSSESSOR_AFTER_NOUN\"]) # 86A genitive + noun\n",
    "cols_87A = select_cols(all_syntax_features_df, [\"ADJECTIVE\",\"S_ADJECTIVE_BEFORE_NOUN\",\"S_ADJECTIVE_AFTER_NOUN\"]) # 87A adjective + noun\n",
    "cols_88A = select_cols(all_syntax_features_df, [\"DEMONSTRATIVE\"]) # 88A demonstrative + noun\n",
    "cols_89A = select_cols(all_syntax_features_df, [\"NUMERAL\"]) # 89A numeral + noun\n",
    "cols_90A = select_cols(all_syntax_features_df, [\"RELATIVE\"]) # 90A relative clause + noun\n",
    "\n",
    "# flatten everything into one list of interesting columns\n",
    "interesting_cols = (\n",
    "    cols_49A + cols_50A + cols_81A +\n",
    "    cols_85A + cols_86A + cols_87A +\n",
    "    cols_88A + cols_89A + cols_90A\n",
    ")\n",
    "\n",
    "# keep only these columns in a new dataframe\n",
    "focus_syntax_features_df = all_syntax_features_df[interesting_cols].copy()\n",
    "\n",
    "print(\"shape (focused on 49A, 50A, 81A, 85A–90A):\", focus_syntax_features_df.shape)\n",
    "print(\"first few columns:\", focus_syntax_features_df.columns[:10].tolist())\n",
    "display(focus_syntax_features_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5359d",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "622dce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(row, col):\n",
    "    v = row[col]\n",
    "    # Handle missing/placeholder values\n",
    "    if pd.isna(v) or v == '--':\n",
    "        return 0.0\n",
    "    return float(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9323cc",
   "metadata": {},
   "source": [
    "# Greenberg Rule 3\n",
    "Languages with dominant VSO order are always prepositional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc926589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVO</th>\n",
       "      <th>SOV</th>\n",
       "      <th>VSO</th>\n",
       "      <th>VOS</th>\n",
       "      <th>OVS</th>\n",
       "      <th>OSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>preposition</th>\n",
       "      <td>326</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postposition</th>\n",
       "      <td>46</td>\n",
       "      <td>381</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SVO  SOV  VSO  VOS  OVS  OSV\n",
       "preposition   326   17   96   39    3    0\n",
       "postposition   46  381    6    0   10    3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# map each word order to its column name\n",
    "wo_cols = {}\n",
    "for wo in [\"SVO\", \"SOV\", \"VSO\", \"VOS\", \"OVS\", \"OSV\"]:\n",
    "    for c in cols_81A:\n",
    "        if wo in c:\n",
    "            wo_cols[wo] = c\n",
    "            break\n",
    "# pick the specific columns for adposition before/after the noun\n",
    "adp_before_col = \"S_ADPOSITION_BEFORE_NOUN\"\n",
    "adp_after_col  = \"S_ADPOSITION_AFTER_NOUN\"\n",
    "\n",
    "# initialize counts dict for each word order and adposition type\n",
    "\n",
    "counts = {\n",
    "    \"preposition\":  {wo: 0 for wo in wo_cols.keys()},\n",
    "    \"postposition\": {wo: 0 for wo in wo_cols.keys()},\n",
    "}\n",
    "\n",
    "# iterate over languages\n",
    "\n",
    "for lang, row in focus_syntax_features_df.iterrows():\n",
    "    # check if preposition or postposition\n",
    "    before = get_val(row, adp_before_col)\n",
    "    after  = get_val(row, adp_after_col)\n",
    "\n",
    "    if before > 0 and after == 0:\n",
    "        row_type = \"preposition\"\n",
    "    elif after > 0 and before == 0:\n",
    "        row_type = \"postposition\"\n",
    "    else:\n",
    "        continue  # skip mixed cases\n",
    "\n",
    "    # Check each word-order column\n",
    "    for wo, col_name in wo_cols.items():\n",
    "        if get_val(row, col_name) > 0:\n",
    "            counts[row_type][wo] += 1\n",
    "\n",
    "# convert to dataframe\n",
    "df_wo_vs_adp = pd.DataFrame.from_dict(counts, orient=\"index\")\n",
    "display(df_wo_vs_adp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15acb25b",
   "metadata": {},
   "source": [
    "According to WALS data 6 languages with VSO order use postpositions and thus violate greenberg #3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b3882",
   "metadata": {},
   "source": [
    "# Greenberg Rule 4\n",
    "With overwhelmingly more than chance frequency, languages with normal SOV order are postpositional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bffa44d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Greenberg Rule 4: SOV vs (pre/post)position\n",
      "adp_type          postposition  preposition\n",
      "word_order_group                           \n",
      "SOV                        381           17\n",
      "non-SOV                    172          487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>adp_type</th>\n",
       "      <th>postposition</th>\n",
       "      <th>preposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_order_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SOV</th>\n",
       "      <td>381</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-SOV</th>\n",
       "      <td>172</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "adp_type          postposition  preposition\n",
       "word_order_group                           \n",
       "SOV                        381           17\n",
       "non-SOV                    172          487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sov_col = [c for c in cols_81A if \"SOV\" in c][0]\n",
    "adp_before_col = \"S_ADPOSITION_BEFORE_NOUN\"\n",
    "adp_after_col  = \"S_ADPOSITION_AFTER_NOUN\"\n",
    "\n",
    "# build a cross table beteween SOV/non-SOV and pre/postposition\n",
    "records = []\n",
    "\n",
    "for lang, row in focus_syntax_features_df.iterrows():\n",
    "    # word order group\n",
    "    is_SOV = get_val(row, sov_col) > 0\n",
    "    wo_group = \"SOV\" if is_SOV else \"non-SOV\"\n",
    "\n",
    "    # adposition type\n",
    "    before = get_val(row, adp_before_col)\n",
    "    after  = get_val(row, adp_after_col)\n",
    "\n",
    "    if before > 0 and after == 0:\n",
    "        adp_type = \"preposition\"\n",
    "    elif after > 0 and before == 0:\n",
    "        adp_type = \"postposition\"\n",
    "    else:\n",
    "        adp_type = \"mixed/other\"  # ambiguous cases\n",
    "\n",
    "    records.append({\n",
    "        \"language\": lang,\n",
    "        \"word_order_group\": wo_group,\n",
    "        \"adp_type\": adp_type\n",
    "    })\n",
    "\n",
    "df_rule4 = pd.DataFrame.from_records(records).set_index(\"language\")\n",
    "\n",
    "# create dataframe\n",
    "mask = df_rule4[\"adp_type\"].isin([\"preposition\", \"postposition\"])\n",
    "df_rule4_clear = df_rule4[mask]\n",
    "\n",
    "table_rule4 = pd.crosstab(\n",
    "    df_rule4_clear[\"word_order_group\"],\n",
    "    df_rule4_clear[\"adp_type\"]\n",
    ")\n",
    "\n",
    "display(table_rule4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b5830d",
   "metadata": {},
   "source": [
    "381 out of 398 SOV languages are postpositional. \n",
    "This confirms that SOV languages have a strong tendency to be postpositional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f5361",
   "metadata": {},
   "source": [
    "## Greenberg Rule 5\n",
    "If a language has dominant SOV order and the genitive follows the governing noun, then the adjective likewise follows the noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59e624ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages with SOV=1 and POSSESSOR_AFTER_NOUN=1: 55\n",
      "… of which ADJECTIVE_AFTER=1: 43\n",
      "… of which ADJECTIVE_BEFORE=1: 8\n"
     ]
    }
   ],
   "source": [
    "df = all_syntax_features_df\n",
    "\n",
    "df_filtered = df[\n",
    "    (df[\"S_SOV\"] == 1) &\n",
    "    (df[\"S_POSSESSOR_AFTER_NOUN\"] == 1)\n",
    "]\n",
    "\n",
    "count_adj_after  = (df_filtered[\"S_ADJECTIVE_AFTER_NOUN\"] == 1).sum()\n",
    "count_adj_before = (df_filtered[\"S_ADJECTIVE_BEFORE_NOUN\"] == 1).sum()\n",
    "\n",
    "print(\"Languages with SOV=1 and POSSESSOR_AFTER_NOUN=1:\", len(df_filtered))\n",
    "print(\"… of which ADJECTIVE_AFTER=1:\", count_adj_after)\n",
    "print(\"… of which ADJECTIVE_BEFORE=1:\", count_adj_before)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac39af6",
   "metadata": {},
   "source": [
    "In 43 out of 55 languages with SOV and genetive follows the governing noun greenberg rule 5 holds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
