{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "699e81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lang2vec.lang2vec as l2v\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3282ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 103)\n",
      "first few rows:\n",
      "     S_SVO  S_SOV  S_VSO  S_VOS  S_OVS  S_OSV  S_SUBJECT_BEFORE_VERB  \\\n",
      "eng    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
      "deu    1.0    1.0    0.0    0.0    0.0    0.0                    1.0   \n",
      "spa    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
      "rus    1.0    0.0    0.0    0.0    0.0    0.0                    1.0   \n",
      "jpn    0.0    1.0    0.0    0.0    0.0    0.0                    1.0   \n",
      "\n",
      "     S_SUBJECT_AFTER_VERB  S_OBJECT_AFTER_VERB  S_OBJECT_BEFORE_VERB  ...  \\\n",
      "eng                   0.0                  1.0                   0.0  ...   \n",
      "deu                   0.0                  1.0                   1.0  ...   \n",
      "spa                   1.0                  1.0                   0.0  ...   \n",
      "rus                   0.0                  1.0                   0.0  ...   \n",
      "jpn                   0.0                  0.0                   1.0  ...   \n",
      "\n",
      "     S_XVO  S_XOV  S_OXV  S_OVX  S_OBLIQUE_AFTER_VERB  S_OBLIQUE_AFTER_OBJECT  \\\n",
      "eng    0.0    0.0    0.0    0.0                   1.0                     1.0   \n",
      "deu    NaN    NaN    NaN    NaN                   NaN                     NaN   \n",
      "spa    0.0    0.0    0.0    0.0                   1.0                     1.0   \n",
      "rus    NaN    NaN    NaN    NaN                   NaN                     NaN   \n",
      "jpn    NaN    NaN    NaN    NaN                   NaN                     NaN   \n",
      "\n",
      "     S_OBLIQUE_BEFORE_VERB  S_OBLIQUE_BEFORE_OBJECT  \\\n",
      "eng                    0.0                      0.0   \n",
      "deu                    NaN                      NaN   \n",
      "spa                    0.0                      0.0   \n",
      "rus                    NaN                      NaN   \n",
      "jpn                    NaN                      NaN   \n",
      "\n",
      "     S_ARTICLE_WORD_BEFORE_NOUN  S_ARTICLE_WORD_AFTER_NOUN  \n",
      "eng                         NaN                        NaN  \n",
      "deu                         NaN                        NaN  \n",
      "spa                         NaN                        NaN  \n",
      "rus                         NaN                        NaN  \n",
      "jpn                         NaN                        NaN  \n",
      "\n",
      "[5 rows x 103 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/npxtp1vs3qn7bdljn2ls4j200000gn/T/ipykernel_29990/3097230125.py:38: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(\"--\", np.nan)\n",
      "/var/folders/qp/npxtp1vs3qn7bdljn2ls4j200000gn/T/ipykernel_29990/3097230125.py:41: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df = df.apply(pd.to_numeric, errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "languages = [\n",
    "    \"eng\",\n",
    "    \"deu\",\n",
    "    \"spa\",\n",
    "    \"rus\",\n",
    "    \"jpn\",\n",
    "    \"hin\",\n",
    "    \"tur\",\n",
    "    \"ara\",\n",
    "    \"por\",\n",
    "    \"ita\",\n",
    "  ]\n",
    "\n",
    "# iso_code -> feature_vector\n",
    "features_dict = l2v.get_features(languages, \"syntax_wals\", header=True)\n",
    "\n",
    "# extract feature names from the special 'CODE' entry\n",
    "feature_names = features_dict[\"CODE\"]\n",
    "\n",
    "# build a matrix for all languages\n",
    "# missing values are encoded as the string '--'\n",
    "rows = []\n",
    "valid_langs = []\n",
    "\n",
    "for lang in languages:\n",
    "    # some languages might not be available; skip if not present\n",
    "    if lang not in features_dict:\n",
    "        print(f\"[warning] language {lang} not available, skipping.\")\n",
    "        continue\n",
    "\n",
    "    rows.append(features_dict[lang])\n",
    "    valid_langs.append(lang)\n",
    "\n",
    "# each row is a language, each column is a wals feature\n",
    "df = pd.DataFrame(rows, index=valid_langs, columns=feature_names)\n",
    "\n",
    "# replace the missing marker '--' with np.nan so pandas can handle it\n",
    "df = df.replace(\"--\", np.nan)\n",
    "\n",
    "# convert numeric strings to floats\n",
    "df = df.apply(pd.to_numeric, errors=\"ignore\")\n",
    "\n",
    "# load wals syntax features into a dataframe\n",
    "print(\"shape:\", df.shape)\n",
    "print(\"first few rows:\")\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wals-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
